{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11959,"sourceType":"datasetVersion","datasetId":8544}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom tqdm import tqdm\n\ndef prepare_food101_dataset(source_dir, target_dir, split_ratio=0.5):\n    \"\"\"\n    Prepare Food-101 dataset by selecting random subset of images.\n    \n    Parameters:\n    source_dir: Original Food-101 dataset directory path\n    target_dir: Target directory where the subset will be created\n    split_ratio: Ratio of images to select (default: 0.5 for 50%)\n    \"\"\"\n    \n    # Create main directories\n    train_dir = os.path.join(target_dir, 'train')\n    test_dir = os.path.join(target_dir, 'test')\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)\n    \n    # Get list of all food classes, filtering out hidden files\n    images_dir = os.path.join(source_dir, 'images')\n    food_classes = [f for f in os.listdir(images_dir) \n                   if not f.startswith('.') and os.path.isdir(os.path.join(images_dir, f))]\n    \n    print(f\"Processing {len(food_classes)} food classes...\")\n    \n    # Process each food class\n    for food_class in tqdm(food_classes):\n        # Create directories for this class\n        os.makedirs(os.path.join(train_dir, food_class), exist_ok=True)\n        os.makedirs(os.path.join(test_dir, food_class), exist_ok=True)\n        \n        # Get all images for this class, filtering out hidden files\n        source_class_dir = os.path.join(source_dir, 'images', food_class)\n        all_images = [f for f in os.listdir(source_class_dir) \n                     if not f.startswith('.') and f.endswith('.jpg')]\n        \n        # Calculate number of images for training\n        num_train = int(len(all_images) * split_ratio)\n        \n        # Randomly select images for training\n        train_images = random.sample(all_images, num_train)\n        # Remaining images will be for testing\n        test_images = list(set(all_images) - set(train_images))\n        \n        # Copy training images\n        for img in train_images:\n            src = os.path.join(source_class_dir, img)\n            dst = os.path.join(train_dir, food_class, img)\n            shutil.copy2(src, dst)\n            \n        # Copy testing images\n        for img in test_images:\n            src = os.path.join(source_class_dir, img)\n            dst = os.path.join(test_dir, food_class, img)\n            shutil.copy2(src, dst)\n    \n    print(\"\\nDataset preparation completed!\")\n    print(f\"Created dataset with {len(food_classes)} classes\")\n    print(f\"Target directory: {target_dir}\")\n\n# Example usage:\nif __name__ == \"__main__\":\n    # Adjust these paths according to your setup\n    SOURCE_DIR = \"/kaggle/input/food-101/food-101/food-101\"  # Original Food-101 dataset directory\n    TARGET_DIR = \"/kaggle/working\"  # Where to create the new dataset\n    \n    prepare_food101_dataset(SOURCE_DIR, TARGET_DIR, split_ratio=0.5)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:55:52.453965Z","iopub.execute_input":"2024-12-15T15:55:52.454846Z","iopub.status.idle":"2024-12-15T16:04:19.044448Z","shell.execute_reply.started":"2024-12-15T15:55:52.454806Z","shell.execute_reply":"2024-12-15T16:04:19.043692Z"}},"outputs":[{"name":"stdout","text":"Processing 101 food classes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 101/101 [08:26<00:00,  5.01s/it]","output_type":"stream"},{"name":"stdout","text":"\nDataset preparation completed!\nCreated dataset with 101 classes\nTarget directory: /kaggle/working\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport os\nimport gc\n\n# Memory optimization: Clear any existing models/memory\ntf.keras.backend.clear_session()\ngc.collect()\n\n# Constants - Reduced batch size and image size for memory optimization\nIMG_SIZE = (160, 160)  # Reduced from 224x224\nBATCH_SIZE = 16       # Reduced from 32\nEPOCHS = 15\nFINE_TUNE_EPOCHS = 10\n\n# Dataset paths\ntrain_dir = \"/kaggle/working/train\"\ntest_dir = \"/kaggle/working/test\"\n\n# Get number of classes\nnum_classes = len(os.listdir(train_dir))\nprint(f\"Number of classes detected: {num_classes}\")\n\ndef prepare_dataset():\n    print(\"Loading training dataset...\")\n    train_ds = tf.keras.utils.image_dataset_from_directory(\n        train_dir,\n        validation_split=0.2,\n        subset=\"training\",\n        seed=123,\n        image_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        label_mode='categorical'\n    )\n\n    print(\"Loading validation dataset...\")\n    val_ds = tf.keras.utils.image_dataset_from_directory(\n        train_dir,\n        validation_split=0.2,\n        subset=\"validation\",\n        seed=123,\n        image_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        label_mode='categorical'\n    )\n\n    print(\"Loading test dataset...\")\n    test_ds = tf.keras.utils.image_dataset_from_directory(\n        test_dir,\n        image_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        label_mode='categorical',\n        shuffle=False\n    )\n\n    # Memory optimization: Use dataset.map to resize images on the fly\n    resize_and_rescale = tf.keras.Sequential([\n        layers.Rescaling(1./255)\n    ])\n\n    train_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), y),\n                           num_parallel_calls=tf.data.AUTOTUNE)\n    val_ds = val_ds.map(lambda x, y: (resize_and_rescale(x), y),\n                        num_parallel_calls=tf.data.AUTOTUNE)\n    test_ds = test_ds.map(lambda x, y: (resize_and_rescale(x), y),\n                         num_parallel_calls=tf.data.AUTOTUNE)\n\n    # Memory optimization: Configure prefetch\n    AUTOTUNE = tf.data.AUTOTUNE\n    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n    val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n    test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n    return train_ds, val_ds, test_ds\n\ndef create_model(num_classes):\n    print(\"Creating MobileNetV2 model...\") # Changed from EfficientNetB0 to MobileNetV2\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=IMG_SIZE + (3,),\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False\n\n    inputs = layers.Input(shape=IMG_SIZE + (3,))\n    x = base_model(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.2)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    \n    return tf.keras.Model(inputs, outputs)\n\nclass TrainingMonitor(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        # Memory optimization: Clear memory after each epoch\n        gc.collect()\n        print(f\"\\nEpoch {epoch+1} completed\")\n        print(f\"Training Accuracy: {logs['accuracy']:.4f}\")\n        print(f\"Validation Accuracy: {logs['val_accuracy']:.4f}\")\n\ndef main():\n    # Memory optimization: Limit GPU memory growth\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        try:\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n        except RuntimeError as e:\n            print(e)\n\n    print(\"Starting the training process...\")\n    train_ds, val_ds, test_ds = prepare_dataset()\n    \n    print(\"Creating and compiling model...\")\n    model = create_model(num_classes)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    # Show model summary\n    model.summary()\n\n    callbacks = [\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath='/kaggle/working/best_model.keras',\n            save_best_only=True,\n            monitor='val_accuracy'\n        ),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        TrainingMonitor()\n    ]\n\n    print(\"\\nStarting initial training phase...\")\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS,\n        callbacks=callbacks\n    )\n\n    # Memory optimization: Clear some memory before fine-tuning\n    gc.collect()\n\n    print(\"\\nStarting fine-tuning phase...\")\n    base_model = model.layers[1]\n    base_model.trainable = True\n    for layer in base_model.layers[:-30]:\n        layer.trainable = False\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    history_fine = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS + FINE_TUNE_EPOCHS,\n        initial_epoch=EPOCHS,\n        callbacks=callbacks\n    )\n\n    print(\"\\nEvaluating final model...\")\n    test_loss, test_accuracy = model.evaluate(test_ds)\n    print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n    \n    print(\"\\nSaving final model...\")\n    model.save('/kaggle/working/food_classification_model_final.keras')\n    print(\"Training completed successfully!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T16:22:34.054263Z","iopub.execute_input":"2024-12-15T16:22:34.054951Z","iopub.status.idle":"2024-12-15T16:36:37.156310Z","shell.execute_reply.started":"2024-12-15T16:22:34.054896Z","shell.execute_reply":"2024-12-15T16:36:37.155319Z"}},"outputs":[{"name":"stdout","text":"Number of classes detected: 101\nStarting the training process...\nLoading training dataset...\nFound 50500 files belonging to 101 classes.\nUsing 40400 files for training.\nLoading validation dataset...\nFound 50500 files belonging to 101 classes.\nUsing 10100 files for validation.\nLoading test dataset...\nFound 50500 files belonging to 101 classes.\nCreating and compiling model...\nCreating MobileNetV2 model...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ mobilenetv2_1.00_160            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │       \u001b[38;5;34m129,381\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ mobilenetv2_1.00_160            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,387,365\u001b[0m (9.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,387,365</span> (9.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\nStarting initial training phase...\nEpoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734279776.448390     427 service.cc:145] XLA service 0x7888d003b620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734279776.448447     427 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1734279776.448455     427 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  12/2525\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 10ms/step - accuracy: 0.0130 - loss: 5.4066     ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1734279781.863646     427 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2523/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3120 - loss: 3.0197\nEpoch 1 completed\nTraining Accuracy: 0.3912\nValidation Accuracy: 0.4748\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 23ms/step - accuracy: 0.3121 - loss: 3.0191 - val_accuracy: 0.4748 - val_loss: 2.1433\nEpoch 2/15\n\u001b[1m2524/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5123 - loss: 1.9327\nEpoch 2 completed\nTraining Accuracy: 0.5090\nValidation Accuracy: 0.4926\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.5123 - loss: 1.9327 - val_accuracy: 0.4926 - val_loss: 2.1098\nEpoch 3/15\n\u001b[1m2523/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5496 - loss: 1.7694\nEpoch 3 completed\nTraining Accuracy: 0.5467\nValidation Accuracy: 0.4892\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.5496 - loss: 1.7694 - val_accuracy: 0.4892 - val_loss: 2.1845\nEpoch 4/15\n\u001b[1m2523/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5673 - loss: 1.6797\nEpoch 4 completed\nTraining Accuracy: 0.5639\nValidation Accuracy: 0.4932\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.5673 - loss: 1.6797 - val_accuracy: 0.4932 - val_loss: 2.1914\nEpoch 5/15\n\u001b[1m2523/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5796 - loss: 1.6150\nEpoch 5 completed\nTraining Accuracy: 0.5769\nValidation Accuracy: 0.4889\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.5796 - loss: 1.6151 - val_accuracy: 0.4889 - val_loss: 2.2685\nEpoch 6/15\n\u001b[1m2524/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5875 - loss: 1.5822\nEpoch 6 completed\nTraining Accuracy: 0.5864\nValidation Accuracy: 0.4920\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.5875 - loss: 1.5822 - val_accuracy: 0.4920 - val_loss: 2.2989\nEpoch 7/15\n\u001b[1m2520/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5951 - loss: 1.5387\nEpoch 7 completed\nTraining Accuracy: 0.5923\nValidation Accuracy: 0.4873\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - accuracy: 0.5951 - loss: 1.5387 - val_accuracy: 0.4873 - val_loss: 2.3548\n\nStarting fine-tuning phase...\nEpoch 16/25\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3617 - loss: 2.9063\nEpoch 16 completed\nTraining Accuracy: 0.4232\nValidation Accuracy: 0.4750\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 19ms/step - accuracy: 0.3617 - loss: 2.9061 - val_accuracy: 0.4750 - val_loss: 2.1971\nEpoch 17/25\n\u001b[1m2524/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5039 - loss: 1.9244\nEpoch 17 completed\nTraining Accuracy: 0.5217\nValidation Accuracy: 0.5004\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.5039 - loss: 1.9243 - val_accuracy: 0.5004 - val_loss: 2.0553\nEpoch 18/25\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5522 - loss: 1.7033\nEpoch 18 completed\nTraining Accuracy: 0.5659\nValidation Accuracy: 0.5244\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 19ms/step - accuracy: 0.5522 - loss: 1.7033 - val_accuracy: 0.5244 - val_loss: 1.9789\nEpoch 19/25\n\u001b[1m2523/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5870 - loss: 1.5572\nEpoch 19 completed\nTraining Accuracy: 0.5989\nValidation Accuracy: 0.5339\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.5870 - loss: 1.5572 - val_accuracy: 0.5339 - val_loss: 1.9339\nEpoch 20/25\n\u001b[1m2522/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6066 - loss: 1.4557\nEpoch 20 completed\nTraining Accuracy: 0.6183\nValidation Accuracy: 0.5386\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.6066 - loss: 1.4557 - val_accuracy: 0.5386 - val_loss: 1.9113\nEpoch 21/25\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6339 - loss: 1.3655\nEpoch 21 completed\nTraining Accuracy: 0.6438\nValidation Accuracy: 0.5467\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.6339 - loss: 1.3654 - val_accuracy: 0.5467 - val_loss: 1.8884\nEpoch 22/25\n\u001b[1m2524/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6487 - loss: 1.2822\nEpoch 22 completed\nTraining Accuracy: 0.6596\nValidation Accuracy: 0.5512\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 18ms/step - accuracy: 0.6487 - loss: 1.2822 - val_accuracy: 0.5512 - val_loss: 1.8702\nEpoch 23/25\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6681 - loss: 1.2086\nEpoch 23 completed\nTraining Accuracy: 0.6746\nValidation Accuracy: 0.5532\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.6681 - loss: 1.2086 - val_accuracy: 0.5532 - val_loss: 1.8607\nEpoch 24/25\n\u001b[1m2522/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6871 - loss: 1.1315\nEpoch 24 completed\nTraining Accuracy: 0.6941\nValidation Accuracy: 0.5574\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.6871 - loss: 1.1315 - val_accuracy: 0.5574 - val_loss: 1.8605\nEpoch 25/25\n\u001b[1m2524/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7013 - loss: 1.0769\nEpoch 25 completed\nTraining Accuracy: 0.7113\nValidation Accuracy: 0.5599\n\u001b[1m2525/2525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18ms/step - accuracy: 0.7013 - loss: 1.0769 - val_accuracy: 0.5599 - val_loss: 1.8628\n\nEvaluating final model...\n\u001b[1m3157/3157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.5432 - loss: 1.9278\n\nFinal Test Accuracy: 0.5670\n\nSaving final model...\nTraining completed successfully!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport os\nimport gc\n\n# Memory optimization: Clear any existing models/memory\ntf.keras.backend.clear_session()\ngc.collect()\n\n# Constants - Reduced batch size and image size for memory optimization\nIMG_SIZE = (160, 160)  # Reduced from 224x224\nBATCH_SIZE = 32       # Reduced from 32\nEPOCHS = 20\nFINE_TUNE_EPOCHS = 20\n\n# Dataset paths\ntrain_dir = \"/kaggle/working/train\"\ntest_dir = \"/kaggle/working/test\"\n\n# Get number of classes\nnum_classes = len(os.listdir(train_dir))\nprint(f\"Number of classes detected: {num_classes}\")\n\ndef prepare_dataset():\n    print(\"Loading training dataset...\")\n    train_ds = tf.keras.utils.image_dataset_from_directory(\n        train_dir,\n        validation_split=0.2,\n        subset=\"training\",\n        seed=123,\n        image_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        label_mode='categorical'\n    )\n\n    print(\"Loading validation dataset...\")\n    val_ds = tf.keras.utils.image_dataset_from_directory(\n        train_dir,\n        validation_split=0.2,\n        subset=\"validation\",\n        seed=123,\n        image_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        label_mode='categorical'\n    )\n\n    print(\"Loading test dataset...\")\n    test_ds = tf.keras.utils.image_dataset_from_directory(\n        test_dir,\n        image_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        label_mode='categorical',\n        shuffle=False\n    )\n\n    # Memory optimization: Use dataset.map to resize images on the fly\n    resize_and_rescale = tf.keras.Sequential([\n        layers.Rescaling(1./255)\n    ])\n\n    train_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), y),\n                           num_parallel_calls=tf.data.AUTOTUNE)\n    val_ds = val_ds.map(lambda x, y: (resize_and_rescale(x), y),\n                        num_parallel_calls=tf.data.AUTOTUNE)\n    test_ds = test_ds.map(lambda x, y: (resize_and_rescale(x), y),\n                         num_parallel_calls=tf.data.AUTOTUNE)\n\n    # Memory optimization: Configure prefetch\n    AUTOTUNE = tf.data.AUTOTUNE\n    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n    val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n    test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n    return train_ds, val_ds, test_ds\n\ndef create_model(num_classes):\n    print(\"Creating MobileNetV2 model...\") # Changed from EfficientNetB0 to MobileNetV2\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=IMG_SIZE + (3,),\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False\n\n    inputs = layers.Input(shape=IMG_SIZE + (3,))\n    x = base_model(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.2)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    \n    return tf.keras.Model(inputs, outputs)\n\nclass TrainingMonitor(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        # Memory optimization: Clear memory after each epoch\n        gc.collect()\n        print(f\"\\nEpoch {epoch+1} completed\")\n        print(f\"Training Accuracy: {logs['accuracy']:.4f}\")\n        print(f\"Validation Accuracy: {logs['val_accuracy']:.4f}\")\n\ndef main():\n    # Memory optimization: Limit GPU memory growth\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        try:\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n        except RuntimeError as e:\n            print(e)\n\n    print(\"Starting the training process...\")\n    train_ds, val_ds, test_ds = prepare_dataset()\n    \n    print(\"Creating and compiling model...\")\n    model = create_model(num_classes)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    # Show model summary\n    model.summary()\n\n    callbacks = [\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath='/kaggle/working/best_model.keras',\n            save_best_only=True,\n            monitor='val_accuracy'\n        ),\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=3,\n            restore_best_weights=True\n        ),\n        TrainingMonitor()\n    ]\n\n    print(\"\\nStarting initial training phase...\")\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS,\n        callbacks=callbacks\n    )\n\n    # Memory optimization: Clear some memory before fine-tuning\n    gc.collect()\n\n    print(\"\\nStarting fine-tuning phase...\")\n    base_model = model.layers[1]\n    base_model.trainable = True\n    for layer in base_model.layers[:-30]:\n        layer.trainable = False\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    history_fine = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS + FINE_TUNE_EPOCHS,\n        initial_epoch=EPOCHS,\n        callbacks=callbacks\n    )\n\n    print(\"\\nEvaluating final model...\")\n    test_loss, test_accuracy = model.evaluate(test_ds)\n    print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n    \n    print(\"\\nSaving final model...\")\n    model.save('/kaggle/working/food_classification_model_final2.keras')\n    print(\"Training completed successfully!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T17:33:05.837202Z","iopub.execute_input":"2024-12-15T17:33:05.838017Z","iopub.status.idle":"2024-12-15T17:52:45.204535Z","shell.execute_reply.started":"2024-12-15T17:33:05.837979Z","shell.execute_reply":"2024-12-15T17:52:45.203409Z"}},"outputs":[{"name":"stdout","text":"Number of classes detected: 101\nStarting the training process...\nLoading training dataset...\nFound 50500 files belonging to 101 classes.\nUsing 40400 files for training.\nLoading validation dataset...\nFound 50500 files belonging to 101 classes.\nUsing 10100 files for validation.\nLoading test dataset...\nFound 50500 files belonging to 101 classes.\nCreating and compiling model...\nCreating MobileNetV2 model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ mobilenetv2_1.00_160            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │       \u001b[38;5;34m129,381\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ mobilenetv2_1.00_160            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,387,365\u001b[0m (9.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,387,365</span> (9.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\nStarting initial training phase...\nEpoch 1/20\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2932 - loss: 3.0921\nEpoch 1 completed\nTraining Accuracy: 0.3822\nValidation Accuracy: 0.4762\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 34ms/step - accuracy: 0.2933 - loss: 3.0917 - val_accuracy: 0.4762 - val_loss: 2.0970\nEpoch 2/20\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5183 - loss: 1.9104\nEpoch 2 completed\nTraining Accuracy: 0.5170\nValidation Accuracy: 0.4944\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.5183 - loss: 1.9104 - val_accuracy: 0.4944 - val_loss: 2.0408\nEpoch 3/20\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5566 - loss: 1.7189\nEpoch 3 completed\nTraining Accuracy: 0.5527\nValidation Accuracy: 0.4990\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.5566 - loss: 1.7189 - val_accuracy: 0.4990 - val_loss: 2.0539\nEpoch 4/20\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5786 - loss: 1.6170\nEpoch 4 completed\nTraining Accuracy: 0.5750\nValidation Accuracy: 0.4947\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.5786 - loss: 1.6170 - val_accuracy: 0.4947 - val_loss: 2.0792\nEpoch 5/20\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5900 - loss: 1.5503\nEpoch 5 completed\nTraining Accuracy: 0.5879\nValidation Accuracy: 0.5030\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.5900 - loss: 1.5503 - val_accuracy: 0.5030 - val_loss: 2.0952\nEpoch 6/20\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6010 - loss: 1.4916\nEpoch 6 completed\nTraining Accuracy: 0.6013\nValidation Accuracy: 0.5079\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.6010 - loss: 1.4916 - val_accuracy: 0.5079 - val_loss: 2.0985\nEpoch 7/20\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6093 - loss: 1.4644\nEpoch 7 completed\nTraining Accuracy: 0.6078\nValidation Accuracy: 0.4970\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.6093 - loss: 1.4644 - val_accuracy: 0.4970 - val_loss: 2.1622\nEpoch 8/20\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6151 - loss: 1.4202\nEpoch 8 completed\nTraining Accuracy: 0.6140\nValidation Accuracy: 0.4929\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.6151 - loss: 1.4202 - val_accuracy: 0.4929 - val_loss: 2.1975\nEpoch 9/20\n\u001b[1m1260/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6190 - loss: 1.3988\nEpoch 9 completed\nTraining Accuracy: 0.6174\nValidation Accuracy: 0.4959\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.6190 - loss: 1.3988 - val_accuracy: 0.4959 - val_loss: 2.2230\n\nStarting fine-tuning phase...\nEpoch 21/40\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3718 - loss: 2.8923\nEpoch 21 completed\nTraining Accuracy: 0.4350\nValidation Accuracy: 0.4864\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - accuracy: 0.3718 - loss: 2.8919 - val_accuracy: 0.4864 - val_loss: 2.1758\nEpoch 22/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5166 - loss: 1.8540\nEpoch 22 completed\nTraining Accuracy: 0.5377\nValidation Accuracy: 0.5003\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.5166 - loss: 1.8538 - val_accuracy: 0.5003 - val_loss: 2.0889\nEpoch 23/40\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5684 - loss: 1.6152\nEpoch 23 completed\nTraining Accuracy: 0.5827\nValidation Accuracy: 0.5150\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.5684 - loss: 1.6151 - val_accuracy: 0.5150 - val_loss: 2.0155\nEpoch 24/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6020 - loss: 1.4778\nEpoch 24 completed\nTraining Accuracy: 0.6152\nValidation Accuracy: 0.5230\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6021 - loss: 1.4776 - val_accuracy: 0.5230 - val_loss: 1.9659\nEpoch 25/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6303 - loss: 1.3638\nEpoch 25 completed\nTraining Accuracy: 0.6425\nValidation Accuracy: 0.5323\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6303 - loss: 1.3637 - val_accuracy: 0.5323 - val_loss: 1.9359\nEpoch 26/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6536 - loss: 1.2830\nEpoch 26 completed\nTraining Accuracy: 0.6635\nValidation Accuracy: 0.5388\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6536 - loss: 1.2830 - val_accuracy: 0.5388 - val_loss: 1.9138\nEpoch 27/40\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6717 - loss: 1.1943\nEpoch 27 completed\nTraining Accuracy: 0.6798\nValidation Accuracy: 0.5422\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6717 - loss: 1.1943 - val_accuracy: 0.5422 - val_loss: 1.8993\nEpoch 28/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6865 - loss: 1.1292\nEpoch 28 completed\nTraining Accuracy: 0.6964\nValidation Accuracy: 0.5470\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6865 - loss: 1.1291 - val_accuracy: 0.5470 - val_loss: 1.8879\nEpoch 29/40\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7100 - loss: 1.0494\nEpoch 29 completed\nTraining Accuracy: 0.7176\nValidation Accuracy: 0.5494\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7100 - loss: 1.0494 - val_accuracy: 0.5494 - val_loss: 1.8840\nEpoch 30/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7236 - loss: 0.9972\nEpoch 30 completed\nTraining Accuracy: 0.7310\nValidation Accuracy: 0.5504\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7237 - loss: 0.9971 - val_accuracy: 0.5504 - val_loss: 1.8803\nEpoch 31/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7379 - loss: 0.9392\nEpoch 31 completed\nTraining Accuracy: 0.7450\nValidation Accuracy: 0.5539\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7380 - loss: 0.9391 - val_accuracy: 0.5539 - val_loss: 1.8824\nEpoch 32/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7533 - loss: 0.8818\nEpoch 32 completed\nTraining Accuracy: 0.7597\nValidation Accuracy: 0.5551\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7533 - loss: 0.8818 - val_accuracy: 0.5551 - val_loss: 1.8806\nEpoch 33/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7663 - loss: 0.8332\nEpoch 33 completed\nTraining Accuracy: 0.7742\nValidation Accuracy: 0.5571\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7663 - loss: 0.8331 - val_accuracy: 0.5571 - val_loss: 1.8825\nEpoch 34/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7765 - loss: 0.7934\nEpoch 34 completed\nTraining Accuracy: 0.7839\nValidation Accuracy: 0.5584\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7765 - loss: 0.7934 - val_accuracy: 0.5584 - val_loss: 1.8876\nEpoch 35/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7904 - loss: 0.7448\nEpoch 35 completed\nTraining Accuracy: 0.7991\nValidation Accuracy: 0.5589\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7904 - loss: 0.7448 - val_accuracy: 0.5589 - val_loss: 1.8938\nEpoch 36/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8008 - loss: 0.7081\nEpoch 36 completed\nTraining Accuracy: 0.8073\nValidation Accuracy: 0.5600\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8009 - loss: 0.7081 - val_accuracy: 0.5600 - val_loss: 1.8919\nEpoch 37/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8153 - loss: 0.6618\nEpoch 37 completed\nTraining Accuracy: 0.8195\nValidation Accuracy: 0.5604\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8153 - loss: 0.6618 - val_accuracy: 0.5604 - val_loss: 1.8956\nEpoch 38/40\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8235 - loss: 0.6273\nEpoch 38 completed\nTraining Accuracy: 0.8283\nValidation Accuracy: 0.5610\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.8235 - loss: 0.6273 - val_accuracy: 0.5610 - val_loss: 1.9038\nEpoch 39/40\n\u001b[1m1261/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8344 - loss: 0.6009\nEpoch 39 completed\nTraining Accuracy: 0.8387\nValidation Accuracy: 0.5602\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 30ms/step - accuracy: 0.8344 - loss: 0.6008 - val_accuracy: 0.5602 - val_loss: 1.9081\nEpoch 40/40\n\u001b[1m1262/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8446 - loss: 0.5586\nEpoch 40 completed\nTraining Accuracy: 0.8461\nValidation Accuracy: 0.5621\n\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8446 - loss: 0.5586 - val_accuracy: 0.5621 - val_loss: 1.9104\n\nEvaluating final model...\n\u001b[1m1579/1579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.5434 - loss: 1.9656\n\nFinal Test Accuracy: 0.5658\n\nSaving final model...\nTraining completed successfully!\n","output_type":"stream"}],"execution_count":3}]}